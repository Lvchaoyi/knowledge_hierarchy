
自我介绍：
	面试官你好，我叫吕超毅，17年毕业于华中科技大学软件工程学院，现在在shopee video supply团队负责Java开发

	我们的团队职责主要有两块：
	业务层面
		video的创作者相关，包括：创作工具、内容变现、流量激励、任务相关、主播助手
		live相关，面相卖家的内容，包括：直播大屏、直播诊断、AIGC
		内容供给相关，包括：短视频图片的爬取
	技术层面
		数据中台的职责，提供数据服务，包括主播端的实时看板、以及面向运营的一些离线数据的统计和可视化平台

	我在团队中的职责也分两块：
	业务层面
		日常业务owner项目以及代码开发
			技术选型
			输出技术文档
			资源申请
			风险评估
			技术分享
	技术层面
		项目的维护以及架构优化
			日常指标监控
			大促期间的问题定位
			系统的稳定性优化
			告警监控问题处理

	业务团队介绍
		团队职责
			创作者内容供给 主播流量激励、任务体系、创作周报
			卖家内容供给 直播实时大屏 
			视频图片内容供给 商品图爬取，aigc图片产出
			数据中台 实时数据、离线数据 聚合看板
		数据范围
			直播数据
			视频数据
			商品数据
			创作者数据
		


	之前主要参与过的项目有：直播大屏系统（基本的业务代码， 日常的报警监控，es的优化，分库分表）、特征平台（负责架构设计，项目搭建，风险评估），有道少儿英语的订单系统（主要负责订单系统的重构和优化）

	主要的技术栈有：Java全家桶（包括Spring、SpringBoot之类的），数据库包括：MySQL、Redis、MongoDB等，其他中间件的话：kafka、ElasticSearch用过一些


重点项目介绍：
	
	架构图/项目结构图 todo

	数据流转

	组件相关问题
	

	直播大屏
		背景目标
			卖家？需要在dashboard上查看直播的相关数据指标，包括GMV、like、item sold之类，类似与抖音直播看板
		特点
			能够承载高吞吐量5w wps的直播数据，拥有kv、mysql、es、hbase多数据源存储方案，系统高可用，能够进行亚秒级的近实时直播商品数据的查询，为创作者提供了丰富的多口径多维度的直播以及商品数据展示
		难点
			直播数据按地区拆库之后，id地区仍有大量bin log,2天时间1.2t 原因：单场直播的总览数据和分钟数据合并存储，分钟数据格式为map，每次产生一条新的分钟数据时，会对总览数据的某个map中的数据进行累加，bin log为statement，所以占用空间非常大
				解决方案：分地区拆库，合并分钟数据，压缩格式 Kryo序列化（效率高，protobuf不支持原生的java对象序列化）
				数据结构是一个session跟多分钟的map数据吗？对的
			数据更新峰值高，实时和分钟级别数据高峰期qps 3w左右 ，持续时间8分钟，假设数据库upsert每秒5K，那么需要48分钟才能消费完，显然不可接受
				分流，主要指标数据和修正数据分流，主要峰值来源于同一同步的修正数据
				为什么现在qps只有上千？流量被切走了
			数据延迟在大促期间只能保证2min内，主播开播推流后，实时大屏入口迟迟看不见dashboard
				怎么解决？直接监听主播的开播信息
			session更新tps瓶颈，数据都放在一行，导致多线程更新表锁竞争压力大
				拆表0-100，拆分钟数据

		技术挑战
		高吞吐 每日6-8亿条宽表数据，直播大屏峰值5w wps
		低延迟 亚小时搬运亿级别数据，直播实时插入查询亚秒级别
		海量数据 千亿级别卖家数据，es集群商品数据700亿文档，6t存储

		原因：数据维度多 主播维度 主播*商品 主播*直播*商品 时间跨度大 数据要求实时性高，写入场景多，update较多，读取场景稍微少
				演化：
					cronjob 读hdfs 每日百万级数据
						异常数据不兼容
						吞吐量低
						不支持断点续传
					cronjob 调用PrestoSQL 每日亿级数据
						支持数据结构化
						大表支持差
					hive + spark + catalog + kafka + consumer
						支持dag形式的任务编排
						支持断点续传
						sql编写灵活，支持复杂查询
						吞吐量高，kafka容易横向拓展
							db负载高
								做不了读写分离，主读主写
								批插批写不太有效，因为主要是update
								限速削峰 不符合业务场景
								分库分表 已经分了
								tidb 需要付费
							bufferpool 脏页?
							mysql不适合大规模数据
							不适合写多读少场景
							表结构不易变更

			替代方案：kv为辅，hbase为主
			hbase lsm?
			hbase使用场景

		解决方案
		线上问题

		后续优化

		问题：
			大屏为什么不做移动端？ 有的
			kv更新指标如何解决并发问题？	
			kol流量控制如何实现的自动增长？
			hbase存什么
			es存什么
			kv存什么
			mysql存什么

	线上问题
		https://confluence.shopee.io/pages/viewpage.action?pageId=1933551179

	jdk升级
		https://confluence.shopee.io/pages/viewpage.action?pageId=2332565944
		原有gc配置
		    -XX:+UseG1GC
		    -XX:+UnlockExperimentalVMOptions 解锁实验性 JVM 选项	允许使用实验性 GC 相关参数
		    -XX:MaxGCPauseMillis=70 目标最大 GC 暂停时间 70ms	G1 会调整回收策略，尽量满足这个暂停时间目标
		    -XX:G1NewSizePercent=35 新生代最小占比 35%	控制新生代初始大小，提高 YGC（年轻代 GC）吞吐量
		    -XX:G1MaxNewSizePercent=45 新生代最大占比 45%	限制新生代最大大小，防止老年代被挤占
		    -XX:G1MixedGCLiveThresholdPercent=85 老年代对象存活率高于 85% 时不参与 Mixed GC	避免回收高存活率的区域，提高 GC 效率
		    -XX:G1HeapWastePercent=5 允许 5% 的堆内存浪费	让 G1 保留一定的可用空间，提高回收灵活性
		    -XX:InitiatingHeapOccupancyPercent=35 堆占用率超过 35% 时启动并发 GC	让 GC 提前介入，减少 Full GC 可能性
		    -XX:+UseStringDeduplication 开启字符串去重	降低重复字符串的内存占用，减少堆压力
		    -XX:+ExplicitGCInvokesConcurrent System.gc() 触发并发 GC 而非 Full GC	避免 System.gc() 造成长时间 STW
		    -XX:+ParallelRefProcEnabled 并行处理引用	加快 GC 处理弱引用（如 SoftReference、WeakReference）
		    -XX:MaxMetaspaceSize=368m 设置 Metaspace 最大大小 368MB	限制类元数据占用空间，防止 Metaspace OOM
		    -XX:MetaspaceSize=368m 设置 Metaspace 初始大小 368MB	预留一定的类元数据空间，减少扩容时的开销
		痛点 服务偶发性STW时间达到秒级 ccweb 单次gc时长长达800ms，每分钟gc时长（疏散停顿：用于对象拷贝）长达近10s （实际4~5s）每分钟平均6~8次gc
		必要性 面向C端服务不能容忍高延迟
		方案选型 jdk17 zgc jdk21 分代zgc，为了项目稳定性以及兼容现有中间件（spring kafka es等）版本选择了jdk17
		难点 升级需要适配各个中间件的版本，项目稳定性需要保证
		解决 从小型项目开始逐步升级，不同版本灰度发布
		    -XX:+UseZGC
		    -XX:ConcGCThreads="$con_gc_threads" 并发的线程数，越少越好，但是会影响并发阶段的耗时
		    -XX:ParallelGCThreads="$par_gc_threads" STW的线程数，越多越好，降低暂停时间
		    -XX:ZCollectionInterval="$zgc_interval"
		效果 偶发性的长时间STW消失，STW时间缩短到微妙级 ccweb 单次gc最大1ms，每分钟gc时长nms，每分钟30次gc左右


	hbase
		线上问题
			scan操作太多，cpu干限流了
			解决
				scan snapshot
				合并scan操作
				降频
			大量bulk load触发compaction 争抢正常IO
			解决
				调整bulk load策略，降频限制线程数
				

	mysql问题
		版本 5.7
		监控团队集群维度+服务维度
		线上负载
			整体db综合读写比 2 ： 1 整体OPS在 70k ~ 160k左右 （都是主库）
			qps 主从比不同集群有的是 2： 1 有的是1 ： 1
			cc web 1k qps
			cc job 1w qps
			ls job 6~7w qps 24c 32g

		线上配置
		慢查询排查
			有一些慢查询超过1s，不影响正常业务，被认为是mysql的正常抖动

		线上问题
		可用性

	数据指标
		db占用
		es占用
		kafka

	性能优化
		https://confluence.shopee.io/pages/viewpage.action?pageId=2284141477
		直播大屏es：https://confluence.shopee.io/pages/viewpage.action?pageId=2153729220




	有道少儿英语订单系统拆分


项目介绍

这个订单异步化改造主要是对我们订单原有基于线程池的方案就行了一些优化，因为之前我们订单下单后的一些逻辑，包括开课、短信、活动、物流等，都是在用户支付完成后，在线程池中进行的。

这样就可能会导致一些问题：

首先是当订单量如果突增的话，大量订单会导致线程池拒绝的风险，
二是之前的过程中，对于业务执行失败的订单，缺少了异常记录的操作，
三是所有不同类型的业务耦合性太强，希望去对他进行一个拆分，比如说一笔订单支付成功后，活动的执行失败不应该影响后续开课的业务执行。

因此对他进行了优化，当时采用了canal+kafka的方式，我们这边订单支付后的回调接口，是将订单状态由0改为1，所以canal只需要监听订单表的变化订单；发送到kafka中，对于这个topic我创建了一个负责清洗的消费者，会解析canal发送的消息，只过滤状态值从0变为1的订单数据；

之后将订单id再次进行转发；

另外我是将订单后置的履约业务拆分为独立的互不影响的几个子业务，将一些共有的方法抽象为一个抽象类，其中提供了模板方法，每个子业务只需要继承这个抽象类，在其中定义自己的业务码，编写各自的业务逻辑就可以很好的扩展，也方便了以后其他同事的开发。

每个子业务都作为一个消费者组来对支付成功的订单topic进行监听，接受到以后通过orderId就可以还原订单、商品、用户的一些数据信息，通过在redis分布式锁+mongo中记录执行结果，来确保原子性避免重复消费（因为对每个子业务定义了业务码，可以区分）。其次对于执行异常的订单，会根据订单id、业务码记录下来，通过定时任务补偿的方式确保最终一致性。


可能后续会问道或者可以在介绍中补充的问题：

线程池相关，各个参数和提交流程
canal的机制，mysql数据同步
一致性方案
分布式锁
订单量特别大怎么办：读写分离、缓存、分库分表（https://blog.csdn.net/weixin_48182198/article/details/108475822、）


订单系统
	订单流程 下单：不同入口（h5，公众号，app，小程序）->创建订单->支付：不同渠道（支付宝、微信、苹果）->支付回调->履约（开课、发短信、发消息、优惠劵、物流）
	订单信息 商品信息 + 用户信息 + 支付信息 + 履约信息 + 物流信息
	订单状态 初始状态->支付->（支付成功、失败、超时）->（开课中、成功、失败）->（退款中、成功、失败）
	订单实际方案 基于base法则 尽量确保最终一致性 线程池+定时任务xxljob
	订单存在问题 线程池问题：订单量激增导致线程池拒绝、业务没有隔离开、大量线程池容易导致fullgc、没有补偿机制和监控 定时任务问题：@schedule单线程导致任务饿死、任务没有设置优先级、没有监控和报警机制 其他问题：统计类需求和用户 
	重构方案 线程池->kafka消息队列 重试补偿机制 定时任务->xxljob 任务增加逆向操作流程
	遇到问题
	分布式解决方案
	canal
	kafka
	订单数据怎么过滤的？kafka的生产者从哪来？ canal server配置来的
	实际kafka的配置？ 6 partition 有没主从 不知道
	canal的角色 监听的是库还是表 mysql的整个bin log 但是可以过 滤发出的消息 表级别过滤 如何保证有序 消息没有强关联不需要有序，而且每个partition中的消息也是顺序的 消息格式是怎样的 一条消息多大
	kafka 配置如何 多少个topic 一个topic，后续履约流程每个流程一个消费者组，消息订阅发布模式 多少个partition 反正>=3 如何保证接受的消息有序 消费者concurrency和partition保持一致
	消费出现问题如何重试，应该怎么办 首先kafka不支持重试 其次应该保证消费的幂等性，接口层面记录执行日志，以及加上分布式锁
	消息消费出现了并发问题如何解决
			redis分布式锁
	订单系统如何设计 
	表设计问题 订单id 商品快照 其他信息
	状态流转问题 支付 开课 退款
	事务一致性问题 spring事务 单库事务 后续服务拆分就需要分布式事务 seata/ JTA
	数量大了怎么办 分库分表 
	